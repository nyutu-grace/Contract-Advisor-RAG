{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Task Decomposition is the process of breaking down a complex task into smaller, more manageable steps. This can be achieved using techniques like Chain of Thought (CoT) or Tree of Thoughts, which help in systematically addressing each part of the task. It can be done through simple prompting, task-specific instructions, or human inputs.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "#### INDEXING ####\n",
    "\n",
    "# Load Documents\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Embed\n",
    "vectorstore = Chroma.from_documents(documents=splits, \n",
    "                                    embedding=OpenAIEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "#### RETRIEVAL and GENERATION ####\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Question\n",
    "rag_chain.invoke(\"What is Task Decomposition?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documents\n",
    "question = \"What kinds of pets do I like?\"\n",
    "document = \"My favorite pet is a cat.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "num_tokens_from_string(question, \"cl100k_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embd = OpenAIEmbeddings()\n",
    "query_result = embd.embed_query(question)\n",
    "document_result = embd.embed_query(document)\n",
    "len(query_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.8807044730847644\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "similarity = cosine_similarity(query_result, document_result)\n",
    "print(\"Cosine Similarity:\", similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract_text_raptor = extract_text_from_pdf('../data/Evaluation Sets/Raptor Contract.pdf')\n",
    "qa_text_raptor = extract_text_from_pdf('../data/Evaluation Sets/Raptor Q&A.pdf')\n",
    "contract_text_robinson = extract_text_from_pdf('../data/Evaluation Sets/Robinson Advisory.pdf')\n",
    "qa_text_robinson = extract_text_from_pdf('../data/Evaluation Sets/Robinson Q&A.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunking\n",
    "def chunk_text(text, chunk_size=500, overlap=50):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = ' '.join(words[i:i + chunk_size])\n",
    "        chunks.append(chunk)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract_chunks_raptor = chunk_text(qa_text_raptor, chunk_size=300, overlap=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chunks_raptor = chunk_text(contract_text_raptor, chunk_size=300, overlap=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_raptor = [Document(page_content=chunk) for chunk in contract_chunks_raptor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_raptor_qa = [Document(page_content=chunk) for chunk in qa_chunks_raptor]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorstores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Create embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "vectorstore_raptor = FAISS.from_documents(documents_raptor, embeddings)\n",
    "vectorstore_raptor_qa = FAISS.from_documents(documents_raptor_qa, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grace-nyutu/.local/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/home/grace-nyutu/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "\n",
    "# Initialize a cross-encoder model for reranking\n",
    "reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "\n",
    "# Define a function to rerank retrieved documents\n",
    "def rerank_documents(query, retrieved_docs, reranker):\n",
    "    pairs = [(query, doc.page_content) for doc in retrieved_docs]\n",
    "    scores = reranker.predict(pairs)\n",
    "    ranked_docs = sorted(zip(scores, retrieved_docs), key=lambda x: x[0], reverse=True)\n",
    "    return [doc for _, doc in ranked_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_rerank(query, vectorstore, reranker, top_k=5):\n",
    "    retrieved_docs = vectorstore.similarity_search(query, k=top_k)\n",
    "    ranked_docs = rerank_documents(query, retrieved_docs, reranker)\n",
    "    return ranked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pipeline_raptor = RetrievalQA.from_llm(llm=llm, retriever=vectorstore_raptor.as_retriever())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"You are a legal assistant. Answer the question based on the given context.\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the RAG pipeline\n",
    "retrieval_qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore_raptor.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    verbose=True,\n",
    "    chain_type_kwargs={\n",
    "        \"verbose\": True,\n",
    "        \"prompt\": prompt\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Q&A pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_qa_pairs(text):\n",
    "    # Regular expressions for matching questions and answers\n",
    "    question_pattern = re.compile(r'Q\\d+[a-z]?: (.*?)\\n')\n",
    "    answer_pattern = re.compile(r'A\\d+[a-z]?: (.*?)\\n')\n",
    "    \n",
    "    # Find all questions and answers\n",
    "    questions = question_pattern.findall(text)\n",
    "    answers = answer_pattern.findall(text)\n",
    "    \n",
    "    # Group questions and answers\n",
    "    qa_pairs = []\n",
    "    q_index = 0\n",
    "    a_index = 0\n",
    "    \n",
    "    while q_index < len(questions) and a_index < len(answers):\n",
    "        question = questions[q_index].strip()\n",
    "        answer = answers[a_index].strip()\n",
    "        \n",
    "        # Check if the next question or answer is a sub-question/sub-answer\n",
    "        while (q_index + 1 < len(questions) and re.match(r'Q\\d+[a-z]:', questions[q_index + 1]) or\n",
    "               a_index + 1 < len(answers) and re.match(r'A\\d+[a-z]:', answers[a_index + 1])):\n",
    "            sub_questions = []\n",
    "            sub_answers = []\n",
    "            \n",
    "            # Collect sub-questions\n",
    "            while q_index + 1 < len(questions) and re.match(r'Q\\d+[a-z]:', questions[q_index + 1]):\n",
    "                q_index += 1\n",
    "                sub_questions.append(questions[q_index].strip())\n",
    "            \n",
    "            # Collect sub-answers\n",
    "            while a_index + 1 < len(answers) and re.match(r'A\\d+[a-z]:', answers[a_index + 1]):\n",
    "                a_index += 1\n",
    "                sub_answers.append(answers[a_index].strip())\n",
    "            \n",
    "            question += ' ' + ' '.join(sub_questions)\n",
    "            answer += ' ' + ' '.join(sub_answers)\n",
    "        \n",
    "        # Append the Q&A pair to the list\n",
    "        qa_pairs.append({\"question\": question, \"answer\": answer})\n",
    "        \n",
    "        # Move to the next question and answer\n",
    "        q_index += 1\n",
    "        a_index += 1\n",
    "    \n",
    "    return qa_pairs\n",
    "\n",
    "qa_pairs_raptor = parse_qa_pairs(qa_text_raptor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'Under what circumstances and to what extent the Sellers are responsible for a breach of',\n",
       "  'answer': 'Except in the case of fraud, the Sellers have no liability for breach of representations and'},\n",
       " {'question': 'Would the Sellers be responsible if after the closing it is determined that there were',\n",
       "  'answer': 'No'},\n",
       " {'question': 'How much is the escrow amount?',\n",
       "  'answer': 'The escrow amount is equal to $1,000,000.'},\n",
       " {'question': 'Is escrow amount grete then the Retention Amount ?',\n",
       "  'answer': 'No.'},\n",
       " {'question': 'What is the purpose of the escrow?',\n",
       "  'answer': 'To serve as a recourse of the Buyer in case of post-closing adjustments of the purchase price.'},\n",
       " {'question': 'May the Escrow Amount serve as a recourse for the Buyer in case of breach of',\n",
       "  'answer': 'No'},\n",
       " {'question': 'Are there any conditions to the closing?',\n",
       "  'answer': 'No, as the signing and closing are simultaneous.'},\n",
       " {'question': 'Are Change of Control Payments considered a Seller Transaction Expense?',\n",
       "  'answer': 'Yes. (See defining of Sellers Transaction Expenses).'},\n",
       " {'question': 'Would the aggregate amount payable by the Buyer to the Sellers be affected if it is',\n",
       "  'answer': 'Yes (See Section 2.07)'},\n",
       " {'question': 'Does the Buyer need to pay the Employees Closing Bonus Amount directly to the',\n",
       "  'answer': 'No. (See Section 2.10)'},\n",
       " {'question': 'Does any of the Sellers provide a representation with respect to any Tax matters related to',\n",
       "  'answer': 'No. Only the Company provides such a representation.'},\n",
       " {'question': 'Is any of the Sellers bound by a non-competition covenant after the Closing?',\n",
       "  'answer': 'No.'},\n",
       " {'question': 'Whose consent is required for the assignment of the Agreement by the Buyer?',\n",
       "  'answer': 'If the assignment is to an Affiliate or purchaser of all of the Buyer’s assets, no consent is'},\n",
       " {'question': 'Does the Buyer needs the Sellers’ consent in the event of an assignment of the',\n",
       "  'answer': 'No. If the assignment is not part of a sale of all or substantially all of the Buyer’s'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_pairs_raptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation \n",
    "def evaluate_model(qa_pipeline, qa_pairs):\n",
    "    correct = 0\n",
    "    total = len(qa_pairs)\n",
    "    \n",
    "    for qa in qa_pairs:\n",
    "        question = qa['question']\n",
    "        expected_answer = qa['answer']\n",
    "        \n",
    "        # Get the generated answer from the RAG pipeline\n",
    "        generated_answer = qa_pipeline.run(question)\n",
    "        \n",
    "        # Compare the generated answer to the expected answer\n",
    "        if generated_answer.strip().lower() == expected_answer.strip().lower():\n",
    "            correct += 1\n",
    "        else:\n",
    "            print(f\"Question: {question}\")\n",
    "            print(f\"Expected: {expected_answer}\")\n",
    "            print(f\"Generated: {generated_answer}\")\n",
    "            print(\"---\")\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grace-nyutu/.local/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Under what circumstances and to what extent the Sellers are responsible for a breach of\n",
      "Expected: Except in the case of fraud, the Sellers have no liability for breach of representations and\n",
      "Generated: The Sellers are responsible for a breach of representations and warranties only in the case of fraud. In all other circumstances, the Sellers have no liability for such breaches.\n",
      "---\n",
      "Question: Would the Sellers be responsible if after the closing it is determined that there were\n",
      "Expected: No\n",
      "Generated: No, the Sellers would not be responsible if after the closing it is determined that there were inaccuracies in the representation provided by them, even if such inaccuracies are the result of the Sellers’ gross negligence. The Sellers have no liability for breach of representations and warranties except in the case of fraud.\n",
      "---\n",
      "Question: Is escrow amount grete then the Retention Amount ?\n",
      "Expected: No.\n",
      "Generated: No. The escrow amount is not greater than the Retention Amount.\n",
      "---\n",
      "Question: What is the purpose of the escrow?\n",
      "Expected: To serve as a recourse of the Buyer in case of post-closing adjustments of the purchase price.\n",
      "Generated: The purpose of the escrow is to serve as a recourse for the Buyer in case of post-closing adjustments of the purchase price. (See section 2.07(e)).\n",
      "---\n",
      "Question: May the Escrow Amount serve as a recourse for the Buyer in case of breach of\n",
      "Expected: No\n",
      "Generated: No, the Escrow Amount may not serve as a recourse for the Buyer in case of breach of representations by the Company.\n",
      "---\n",
      "Question: Are there any conditions to the closing?\n",
      "Expected: No, as the signing and closing are simultaneous.\n",
      "Generated: No, there are no conditions to the closing as the signing and closing are simultaneous.\n",
      "---\n",
      "Question: Are Change of Control Payments considered a Seller Transaction Expense?\n",
      "Expected: Yes. (See defining of Sellers Transaction Expenses).\n",
      "Generated: Yes, Change of Control Payments are considered a Seller Transaction Expense.\n",
      "---\n",
      "Question: Would the aggregate amount payable by the Buyer to the Sellers be affected if it is\n",
      "Expected: Yes (See Section 2.07)\n",
      "Generated: Yes, the aggregate amount payable by the Buyer to the Sellers would be affected if it is determined that the actual Closing Debt Amount is greater than the estimated Closing Debt Amount. (See Section 2.07)\n",
      "---\n",
      "Question: Does the Buyer need to pay the Employees Closing Bonus Amount directly to the\n",
      "Expected: No. (See Section 2.10)\n",
      "Generated: No, the Buyer does not need to pay the Employees Closing Bonus Amount directly to the Company’s employees. (See Section 2.10)\n",
      "---\n",
      "Question: Does any of the Sellers provide a representation with respect to any Tax matters related to\n",
      "Expected: No. Only the Company provides such a representation.\n",
      "Generated: No, none of the Sellers provide a representation with respect to any Tax matters related to the Company. Only the Company provides such a representation.\n",
      "---\n",
      "Question: Is any of the Sellers bound by a non-competition covenant after the Closing?\n",
      "Expected: No.\n",
      "Generated: No. None of the Sellers are bound by a non-competition covenant after the Closing.\n",
      "---\n",
      "Question: Whose consent is required for the assignment of the Agreement by the Buyer?\n",
      "Expected: If the assignment is to an Affiliate or purchaser of all of the Buyer’s assets, no consent is\n",
      "Generated: If the assignment is to an Affiliate or purchaser of all of the Buyer’s assets, no consent is required. Otherwise, the consent of the Company and the Seller Representative is required.\n",
      "---\n",
      "Question: Does the Buyer needs the Sellers’ consent in the event of an assignment of the\n",
      "Expected: No. If the assignment is not part of a sale of all or substantially all of the Buyer’s\n",
      "Generated: No, the Buyer does not need the Sellers’ consent in the event of an assignment of the Agreement to a third party who is not a Buyer’s Affiliate. However, if the assignment is not part of a sale of all or substantially all of the Buyer’s assets, the assignment requires the consent of the Company and the Seller’s Representative.\n",
      "---\n",
      "Raptor Contract Accuracy: 7.14%\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation\n",
    "accuracy_raptor = evaluate_model(qa_pipeline_raptor, qa_pairs_raptor)\n",
    "print(f\"Raptor Contract Accuracy: {accuracy_raptor * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
